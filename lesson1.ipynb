{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '1', 'name': 'bulbasaur', 'size': {'weight': 6.9, 'height': 0.7}},\n",
       " {'id': '4', 'name': 'charmander', 'size': {'weight': 8.5, 'height': 0.6}},\n",
       " {'id': '25', 'name': 'pikachu', 'size': {'weight': 6, 'height': 0.4}}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [\n",
    "    {\"id\": \"1\", \"name\": \"bulbasaur\", \"size\": {\"weight\": 6.9, \"height\": 0.7}},\n",
    "    {\"id\": \"4\", \"name\": \"charmander\", \"size\": {\"weight\": 8.5, \"height\": 0.6}},\n",
    "    {\"id\": \"25\", \"name\": \"pikachu\", \"size\": {\"weight\": 6, \"height\": 0.4}},\n",
    "]\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlt\n",
    "\n",
    "# Set pipeline name, destination, and dataset name\n",
    "pipeline = dlt.pipeline(\n",
    "    pipeline_name=\"quick_start\",\n",
    "    destination=\"duckdb\",\n",
    "    dataset_name=\"mydata\",\n",
    "    dev_mode = True,\n",
    "    progress=\"log\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You instantiate a pipeline by calling the dlt.pipeline function with the following arguments:\n",
    "\n",
    "**pipeline_name**: This is the name you give to your pipeline. It helps you track and monitor your pipeline, and also helps to bring back its state and data structures for future runs. If you don't give a name, dlt will use the name of the Python file you're running as the pipeline name.\n",
    "\n",
    "**destination**: a name of the destination to which dlt will load the data. It may also be provided to the run method of the pipeline.\n",
    "dataset_name: This is the name of the group of tables (or dataset) where your data will be sent. You can think of a dataset like a folder that holds many files, or a schema in a relational database. You can also specify this later when you run or load the pipeline. If you don't provide a name, it will default to the name of your pipeline.\n",
    "\n",
    "**dev_mode**: If you set this to True, dlt will add a timestamp to your dataset name every time you create a pipeline. This means a new dataset will be created each time you create a pipeline.\n",
    "There are more arguments, but they are for advanced use, we skip it for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------- Extract quick_start ------------------------------\n",
      "Resources: 0/1 (0.0%) | Time: 0.00s | Rate: 0.00/s\n",
      "Memory usage: 174.47 MB (65.10%) | CPU usage: 0.00%\n",
      "\n",
      "----------------------------- Extract quick_start ------------------------------\n",
      "Resources: 0/1 (0.0%) | Time: 0.00s | Rate: 0.00/s\n",
      "pokemon: 1  | Time: 0.00s | Rate: 349525.33/s\n",
      "Memory usage: 174.52 MB (65.10%) | CPU usage: 0.00%\n",
      "\n",
      "----------------------------- Extract quick_start ------------------------------\n",
      "Resources: 1/1 (100.0%) | Time: 0.01s | Rate: 72.41/s\n",
      "pokemon: 3  | Time: 0.01s | Rate: 238.86/s\n",
      "Memory usage: 174.52 MB (65.10%) | CPU usage: 0.00%\n",
      "\n",
      "----------------------------- Extract quick_start ------------------------------\n",
      "Resources: 0/1 (0.0%) | Time: 0.00s | Rate: 0.00/s\n",
      "Memory usage: 174.55 MB (65.10%) | CPU usage: 0.00%\n",
      "\n",
      "----------------------------- Extract quick_start ------------------------------\n",
      "Resources: 0/1 (0.0%) | Time: 0.00s | Rate: 0.00/s\n",
      "_dlt_pipeline_state: 1  | Time: 0.00s | Rate: 322638.77/s\n",
      "Memory usage: 174.58 MB (65.10%) | CPU usage: 0.00%\n",
      "\n",
      "----------------------------- Extract quick_start ------------------------------\n",
      "Resources: 1/1 (100.0%) | Time: 0.02s | Rate: 62.65/s\n",
      "_dlt_pipeline_state: 1  | Time: 0.01s | Rate: 70.76/s\n",
      "Memory usage: 174.59 MB (65.10%) | CPU usage: 0.00%\n",
      "\n",
      "------------------ Normalize quick_start in 1735311426.166811 ------------------\n",
      "Files: 0/2 (0.0%) | Time: 0.00s | Rate: 0.00/s\n",
      "Memory usage: 175.45 MB (65.10%) | CPU usage: 0.00%\n",
      "\n",
      "------------------ Normalize quick_start in 1735311426.166811 ------------------\n",
      "Files: 0/2 (0.0%) | Time: 0.00s | Rate: 0.00/s\n",
      "Items: 0  | Time: 0.00s | Rate: 0.00/s\n",
      "Memory usage: 175.45 MB (65.10%) | CPU usage: 0.00%\n",
      "\n",
      "------------------ Normalize quick_start in 1735311426.166811 ------------------\n",
      "Files: 2/2 (100.0%) | Time: 0.01s | Rate: 334.46/s\n",
      "Items: 4  | Time: 0.01s | Rate: 681.67/s\n",
      "Memory usage: 175.53 MB (65.10%) | CPU usage: 0.00%\n",
      "\n",
      "-------------------- Load quick_start in 1735311426.166811 ---------------------\n",
      "Jobs: 0/2 (0.0%) | Time: 0.00s | Rate: 0.00/s\n",
      "Memory usage: 175.67 MB (65.10%) | CPU usage: 0.00%\n",
      "\n",
      "-------------------- Load quick_start in 1735311426.166811 ---------------------\n",
      "Jobs: 2/2 (100.0%) | Time: 0.06s | Rate: 32.41/s\n",
      "Memory usage: 191.36 MB (65.10%) | CPU usage: 0.00%\n",
      "\n",
      "Pipeline quick_start load step completed in 0.06 seconds\n",
      "1 load package(s) were loaded to destination duckdb and into dataset mydata_20241227025703\n",
      "The duckdb destination used duckdb:////Users/m/code/dlt_course/quick_start.duckdb location to store data\n",
      "Load package 1735311426.166811 is LOADED and contains no failed jobs\n"
     ]
    }
   ],
   "source": [
    "# Run the pipeline with data and table name\n",
    "load_info = pipeline.run(data, write_disposition=\"replace\", table_name=\"pokemon\")\n",
    "\n",
    "print(load_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commonly used arguments:\n",
    "\n",
    "* **data** (the first argument) may be a dlt source, resource, generator function, or any Iterator or Iterable (i.e., a list or the result of the map function).\n",
    "* **write_disposition** controls how to write data to a table. Defaults to \"append\".\n",
    "    * `append` will always add new data at the end of the table.\n",
    "    * `replace` will replace existing data with new data.\n",
    "    * `skip` will prevent data from loading.\n",
    "    * `merge` will deduplicate and merge data based on primary_key and merge_key hints.\n",
    "* **table_name**: specified in cases when the table name cannot be inferred, i.e., from the resources or name of the generator function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can quickly inspect the generated tables, the data, see how many rows were loaded to which table,\n",
    "# do SQL queries, etc., by executing the following command from the same folder as your script\n",
    "\n",
    "# streamlit should be installed\n",
    "%%capture\n",
    "uv add streamlit\n",
    "\n",
    "\n",
    "%%capture\n",
    "dlt pipeline quick_start show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the pipeline name you defined in your Python code with the pipeline_name argument. If you are unsure, you can use the following command to list all pipelines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlt pipeline --list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore the loaded data:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### **(1) DuckDB Connection**\n",
    "\n",
    "Start a connection to your database using native duckdb connection and look what tables were generated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>database</th>\n",
       "      <th>schema</th>\n",
       "      <th>name</th>\n",
       "      <th>column_names</th>\n",
       "      <th>column_types</th>\n",
       "      <th>temporary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>quick_start</td>\n",
       "      <td>mydata_20241227020710</td>\n",
       "      <td>_dlt_loads</td>\n",
       "      <td>[load_id, schema_name, status, inserted_at, sc...</td>\n",
       "      <td>[VARCHAR, VARCHAR, BIGINT, TIMESTAMP WITH TIME...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>quick_start</td>\n",
       "      <td>mydata_20241227020710</td>\n",
       "      <td>_dlt_pipeline_state</td>\n",
       "      <td>[version, engine_version, pipeline_name, state...</td>\n",
       "      <td>[BIGINT, BIGINT, VARCHAR, VARCHAR, TIMESTAMP W...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>quick_start</td>\n",
       "      <td>mydata_20241227020710</td>\n",
       "      <td>_dlt_version</td>\n",
       "      <td>[version, engine_version, inserted_at, schema_...</td>\n",
       "      <td>[BIGINT, BIGINT, TIMESTAMP WITH TIME ZONE, VAR...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>quick_start</td>\n",
       "      <td>mydata_20241227020710</td>\n",
       "      <td>pokemon</td>\n",
       "      <td>[id, name, size__weight, size__height, _dlt_lo...</td>\n",
       "      <td>[VARCHAR, VARCHAR, DOUBLE, DOUBLE, VARCHAR, VA...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      database                 schema                 name  \\\n",
       "0  quick_start  mydata_20241227020710           _dlt_loads   \n",
       "1  quick_start  mydata_20241227020710  _dlt_pipeline_state   \n",
       "2  quick_start  mydata_20241227020710         _dlt_version   \n",
       "3  quick_start  mydata_20241227020710              pokemon   \n",
       "\n",
       "                                        column_names  \\\n",
       "0  [load_id, schema_name, status, inserted_at, sc...   \n",
       "1  [version, engine_version, pipeline_name, state...   \n",
       "2  [version, engine_version, inserted_at, schema_...   \n",
       "3  [id, name, size__weight, size__height, _dlt_lo...   \n",
       "\n",
       "                                        column_types  temporary  \n",
       "0  [VARCHAR, VARCHAR, BIGINT, TIMESTAMP WITH TIME...      False  \n",
       "1  [BIGINT, BIGINT, VARCHAR, VARCHAR, TIMESTAMP W...      False  \n",
       "2  [BIGINT, BIGINT, TIMESTAMP WITH TIME ZONE, VAR...      False  \n",
       "3  [VARCHAR, VARCHAR, DOUBLE, DOUBLE, VARCHAR, VA...      False  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import duckdb\n",
    "\n",
    "# Connect to the DuckDB database\n",
    "conn = duckdb.connect(f\"{pipeline.pipeline_name}.duckdb\")\n",
    "\n",
    "# Set search path to the dataset\n",
    "conn.sql(f\"SET search_path = '{pipeline.dataset_name}'\")\n",
    "\n",
    "# Describe the dataset\n",
    "conn.sql(\"DESCRIBE\").df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see:\n",
    "-  `pokemon` table,\n",
    "\n",
    "and 3 special `dlt` tables (we will discuss them later):\n",
    "- `_dlt_loads`,\n",
    "- `_dlt_pipeline_state`,\n",
    "- `_dlt_version`.\n",
    "\n",
    "Let's execute a query to get all data from the `pokemon` table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>size__weight</th>\n",
       "      <th>size__height</th>\n",
       "      <th>_dlt_load_id</th>\n",
       "      <th>_dlt_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>bulbasaur</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1735308434.035593</td>\n",
       "      <td>cs6TssI83RzuBw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>charmander</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1735308434.035593</td>\n",
       "      <td>Ab4oNZ6NilLpnw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>pikachu</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1735308434.035593</td>\n",
       "      <td>IKyX5JlTDzi6eQ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id        name  size__weight  size__height       _dlt_load_id  \\\n",
       "0   1   bulbasaur           6.9           0.7  1735308434.035593   \n",
       "1   4  charmander           8.5           0.6  1735308434.035593   \n",
       "2  25     pikachu           6.0           0.4  1735308434.035593   \n",
       "\n",
       "          _dlt_id  \n",
       "0  cs6TssI83RzuBw  \n",
       "1  Ab4oNZ6NilLpnw  \n",
       "2  IKyX5JlTDzi6eQ  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetch all data from 'pokemon' as a DataFrame\n",
    "table = conn.sql(\"SELECT * FROM pokemon\").df()\n",
    "\n",
    "# Display the DataFrame\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ---\n",
    " ### **(2) `dlt`'s [sql_client](https://dlthub.com/docs/general-usage/dataset-access/sql-client)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most dlt destinations (even filesystem) use an implementation of the `SqlClientBase` class to connect to the physical destination to which your data is loaded. You can access the SQL client of your destination via the `sql_client` method on your pipeline.\n",
    "\n",
    "Start a connection to your database with `pipeline.sql_client()` and execute a query to get all data from the `pokemon` table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>size__weight</th>\n",
       "      <th>size__height</th>\n",
       "      <th>_dlt_load_id</th>\n",
       "      <th>_dlt_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>bulbasaur</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1735308434.035593</td>\n",
       "      <td>cs6TssI83RzuBw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>charmander</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1735308434.035593</td>\n",
       "      <td>Ab4oNZ6NilLpnw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>pikachu</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1735308434.035593</td>\n",
       "      <td>IKyX5JlTDzi6eQ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id        name  size__weight  size__height       _dlt_load_id  \\\n",
       "0   1   bulbasaur           6.9           0.7  1735308434.035593   \n",
       "1   4  charmander           8.5           0.6  1735308434.035593   \n",
       "2  25     pikachu           6.0           0.4  1735308434.035593   \n",
       "\n",
       "          _dlt_id  \n",
       "0  cs6TssI83RzuBw  \n",
       "1  Ab4oNZ6NilLpnw  \n",
       "2  IKyX5JlTDzi6eQ  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query data from 'pokemon' using the SQL client\n",
    "with pipeline.sql_client() as client:\n",
    "    with client.execute_query(\"SELECT * FROM pokemon\") as cursor:\n",
    "        data = cursor.df()\n",
    "\n",
    "# Display the data\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### **(3) dlt [datasets](https://dlthub.com/docs/general-usage/dataset-access/dataset)**\n",
    "\n",
    "Here's an example of how to retrieve data from a pipeline and load it into a Pandas DataFrame or a PyArrow Table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>size__weight</th>\n",
       "      <th>size__height</th>\n",
       "      <th>_dlt_load_id</th>\n",
       "      <th>_dlt_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>bulbasaur</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1735308434.035593</td>\n",
       "      <td>cs6TssI83RzuBw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>charmander</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1735308434.035593</td>\n",
       "      <td>Ab4oNZ6NilLpnw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>pikachu</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1735308434.035593</td>\n",
       "      <td>IKyX5JlTDzi6eQ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id        name  size__weight  size__height       _dlt_load_id  \\\n",
       "0   1   bulbasaur           6.9           0.7  1735308434.035593   \n",
       "1   4  charmander           8.5           0.6  1735308434.035593   \n",
       "2  25     pikachu           6.0           0.4  1735308434.035593   \n",
       "\n",
       "          _dlt_id  \n",
       "0  cs6TssI83RzuBw  \n",
       "1  Ab4oNZ6NilLpnw  \n",
       "2  IKyX5JlTDzi6eQ  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pipeline.dataset(dataset_type=\"default\")\n",
    "pandas_df = dataset.pokemon.df()\n",
    "\n",
    "pandas_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# **Exercise 1**\n",
    "\n",
    "Using the code from the previous cell, fetch the data from the `pokemon` table into a dataframe and count the number of columns in the table `pokemon`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pandas_df.columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
